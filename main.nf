#!/usr/bin/env nextflow
/*
================================================================================
--------------------------------------------------------------------------------
      NEXTFLOW pipeline for smallRNAseq analysis
         provided by @zhangdongqin2@126.com 
--------------------------------------------------------------------------------
================================================================================
smallRNAseq pipeline is a quick and easy pipeline deploy on linux/Mac system.
This pipeline is supported run on specified conda environment.
You can use environment.yml to create a conda environment for this pipeline.
You can run this pipeline on local conda env by < -with-conda /path/to/conda/env >
This pipeline is desiged and implement by Zhang.DQ < zhangdongqin2@126.com >
Pipeline visualization is supported by nf-core
================================================================================
*/

ANSI_RESET = "\u001B[0m";
ANSI_BLACK = "\u001B[30m";
ANSI_RED = "\u001B[31m";
ANSI_GREEN = "\u001B[32m";
ANSI_YELLOW = "\u001B[33m";
ANSI_BLUE = "\u001B[34m";
ANSI_PURPLE = "\u001B[35m";
ANSI_CYAN = "\u001B[36m";
ANSI_WHITE = "\u001B[37m";
def print_red = {  str -> ANSI_RED + str + ANSI_RESET }
def print_black = {  str -> ANSI_BLACK + str + ANSI_RESET }
def print_green = {  str -> ANSI_GREEN + str + ANSI_RESET }
def print_yellow = {  str -> ANSI_YELLOW + str + ANSI_RESET }
def print_blue = {  str -> ANSI_BLUE + str + ANSI_RESET }
def print_cyan = {  str -> ANSI_CYAN + str + ANSI_RESET }
def print_purple = {  str -> ANSI_PURPLE + str + ANSI_RESET }
def print_white = {  str -> ANSI_WHITE + str + ANSI_RESET }

nextflow.enable.dsl = 2

def helpMessage() {
    log.info nfcoreHeader()
    log.info"""
    A Nextflow-based miRNAseq Analysis Pipeline,version:$params.version
    Usage:

    The typical command for running the pipeline is as follows:

    nextflow run main.nf --reads 'reads/*.fq.gz'

    Required arguments:
      --reads          [file]           Path to input data (must be surrounded with quotes) < 'reads/*.fq.gz' >

    Optional arguments:
      --protocol        [str]           Sequencing protocol, default is 'illumina'
      --species         [str]           Species name of reads, default is 'hsa'
      --hairpin        [file]           Path to hairpin microRNA fasta
      --mature         [file]           Path to mature microRNA fasta          
      --gtf            [path]           Path to hsa.gff3 or other species 
      --genome         [path]           Path to reference genome fasta file 
      --help            [str]           Help information for RNAseq pipeline
      --cpus            [int]           Cpu cores for pipeline , default is 6, you can specify core numbers with < --cpu 8 >
      --bowtie_index   [path]           Path to bowtie_index,if you want to mapping smallRNA sequencing data to ref genome ,you can specify this argument
      --outdir         [path]           Path to analysis results directory ,defalut is < ./results >.
      --salmon         [bool]           Specify use salmon quant to quantify miRNA counts
      --genome_mapping [bool]           Defalut is true,you can specify false to skip genome mapping
    Other Options:
      --debug        [bool]           Flag to run only specific fusion tool/s and not the whole pipeline. Only works on tool flags.
      --outdir       [file]           The output directory where the results will be saved
      --email       [email]           Set this parameter to your e-mail address to get a summary e-mail with details of the run sent to you when the workflow exits
      --email_on_fail[email]          Same as --email, except only send mail if the workflow is not successful
      --max_multiqc_email_size [str]  Theshold size for MultiQC report to be attached in notification email. If file generated by pipeline exceeds the threshold, it will not be attached (Default: 25MB)
      -name [str]                     Name for the pipeline run. If not specified, Nextflow will automatically generate a random mnemonic

    AWSBatch options:
      --awsqueue [str]                The AWSBatch JobQueue that needs to be set when running on AWSBatch
      --awsregion [str]               The AWS Region for your AWS Batch job to run on
      --awscli [str]                  Path to the AWS CLI tool
    """.stripIndent()
}

def nfcoreHeader() {
    // Log colors ANSI codes
    c_black = params.monochrome_logs ? '' : "\033[0;30m";
    c_blue = params.monochrome_logs ? '' : "\033[0;34m";
    c_cyan = params.monochrome_logs ? '' : "\033[0;36m";
    c_dim = params.monochrome_logs ? '' : "\033[2m";
    c_green = params.monochrome_logs ? '' : "\033[0;32m";
    c_purple = params.monochrome_logs ? '' : "\033[0;35m";
    c_reset = params.monochrome_logs ? '' : "\033[0m";
    c_white = params.monochrome_logs ? '' : "\033[0;37m";
    c_yellow = params.monochrome_logs ? '' : "\033[0;33m";

    return """    -${c_dim}--------------------------------------------------${c_reset}-
                                            ${c_green},--.${c_black}/${c_green},-.${c_reset}
    ${c_blue}        ___     __   __   __   ___     ${c_green}/,-._.--~\'${c_reset}
    ${c_blue}  |\\ | |__  __ /  ` /  \\ |__) |__         ${c_yellow}}  {${c_reset}
    ${c_blue}  | \\| |       \\__, \\__/ |  \\ |___     ${c_green}\\`-._,-`-,${c_reset}
                                            ${c_green}`._,._,\'${c_reset}
    ${c_purple}  smallRNAseq analysis/@zhangdongqin2@126.com v${workflow.manifest.version}${c_reset}
    -${c_dim}--------------------------------------------------${c_reset}-
    """.stripIndent()
}

if (params.help){
    helpMessage()
    exit 0
}

if (params.reads){ raw_reads = Channel.fromFilePairs(params.reads,size: params.single_end ? 1 : 2 )
                     .ifEmpty{ exit 1, "ERROR:Cannot find any reads matching: ${params.reads}\nNB: Path needs to be enclosed in quotes!" }
           reads_fastp  = Channel.fromFilePairs(params.reads,size: params.single_end ? 1 : 2 )
}

process GET_NEXTFLOW_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE {
   publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

   output:
   path ("*.txt"), emit: software_version
   script:
   """
   echo $workflow.manifest.version > v_pipeline.txt
   echo $workflow.nextflow.version > v_nextflow.txt
   """
}

process GET_FASTQC_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE {
   label 'fastqc'
   publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

   output:
   path ("*.txt"), emit: software_version
   script:
   """
   fastqc --version > v_fastqc.txt
   """
}

process GET_SAMTOOLS_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE {
   label 'samtools'
   publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

   output:
   path ("*.txt"), emit: software_version
   script:
   """
   samtools --version > v_samtools.txt
   """
}

process GET_MULTIQC_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE {
   label 'multiqc'
   publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

   output:
   path ("*.txt"), emit: software_version
   script:
   """
   multiqc --version > v_multiqc.txt
   """
}

process GET_FASTP_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE{
    label 'fastp'
    publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

    output:
    path ("*.txt"), emit: software_version
    script:
    """
    fastp --version > v_fastp.txt
    """
}

process GET_SPADES_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE{
    label 'spades'
    publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

    output:
    path ("*.txt"), emit: software_version
    script:
    """
    spades.py --version > v_spades.txt
    """
}

process GET_UNICYCLER_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE{
    label 'unicycler'
    publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

    output:
    path ("*.txt"), emit: software_version
    script:
    """
    unicycler --version > v_unicycler.txt
    """
}

process GET_QUAST_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE{
    label 'quast'
    publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

    output:
    path ("*.txt"), emit: software_version
    script:
    """
    quast --version > v_quast.txt
    """
}

process GET_PROKKA_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE{
    label 'prokka'
    publishDir "${params.outdir}/pipeline_info", mode: params.publish_dir_mode

    output:
    path ("*.txt"), emit: software_version
    script:
    """
    echo \$(prokka --version 2>&1) > v_prokka.txt
    """
}

process FASTQC_QUALITY_CHECK_FOR_RAW_READS {
    label 'fastqc'
    tag "$sample"
    publishDir "${params.outdir}/raw_fastqc_report", mode: params.publish_dir_mode
    input:
    tuple val(sample), path (reads)
    output:
    tuple val(sample), path("*.html"), emit: html
    tuple val(sample), path("*.zip") , emit: zip
    script:
    if (params.single_end) {
        """
        fastqc --threads $task.cpus ${reads}       
        """
    } else {
        """
        fastqc --threads $task.cpus ${reads[0]} ${reads[1]}
        """
}
}
/*
--------------------------------------------------------------------------------
Define a fastp for raw_reads function for pipeline
--------------------------------------------------------------------------------
*/
process FASTP_READS_FILTER_FOR_RAW_READS {
    label 'fastp'
    tag "$sample"
    publishDir "${params.outdir}/fastp_report", mode: params.publish_dir_mode
    input:
    tuple val(sample), path(reads)
    output:
    tuple val(sample), path('*.clean.fq.gz')  , emit:reads
    tuple val(sample), path('*.clean.fq.gz')  , emit:clean_reads_salmon
    tuple val(sample), path('*.clean.fq.gz')  , emit:clean_reads_hisat2
    tuple val(sample), path('*.json')         , emit: json
    tuple val(sample), path('*.html')         , emit: html
    tuple val(sample), path('*.log')          , emit: log
    tuple val(sample), path('*.fail.fq.gz'), optional:true, emit: reads_fail

    script:
    if (params.single_end) {
    """
        fastp \\
            --in1 ${reads} \\
            --out1 ${sample}.clean.fq.gz \\
            --thread $task.cpus \\
            --json ${sample}.fastp.json \\
            --html ${sample}.fastp.html \\
            --failed_out ${sample}.fail.fq.gz \\
            2> ${sample}.fastp.log
    """

    } else {
    """
        fastp \\
            --in1 ${reads[0]} \\
            --in2 ${reads[1]} \\
            --out1 ${sample}_1.clean.fq.gz \\
            --out2 ${sample}_2.clean.fq.gz \\
            --json ${sample}.fastp.json \\
            --html ${sample}.fastp.html \\
            --unpaired1 ${sample}_1.fail.fq.gz \\
            --unpaired2 ${sample}_2.fail.fq.gz \\
            --thread $task.cpus \\
            --detect_adapter_for_pe \\
            2> ${sample}.fastp.log
    """

    }
}
/*
--------------------------------------------------------------------------------
Define a fastqc for clean_reads function for pipeline
--------------------------------------------------------------------------------
*/
process FASTQC_QUALITY_CHECK_FOR_CLEAN_READS {
    label 'fastqc'
    tag "$sample"
    publishDir "${params.outdir}/clean_fastqc_report", mode: params.publish_dir_mode
    input:
    tuple val(sample), path (reads)
    output:
    tuple val(sample), path("*.html"), emit: html
    tuple val(sample), path("*.zip") , emit: zip
    script:
    if (params.single_end) {
        """
        fastqc --threads $task.cpus ${reads}       
        """
    } else {
        """
        fastqc --threads $task.cpus ${reads[0]} ${reads[1]}
        """
}
}

process SPADES_SEQUENCE_ASSEMBLE_FOR_FASTP_FILTED_RAW_READS {
  label 'spades'
  tag "$sample"
  publishDir "${params.outdir}/genome_assemble_results/spades", mode: params.publish_dir_mode
  input:
  tuple val(sample), path (reads)
  output:
  tuple val(sample), path("spades_out") , emit: results
  script:
  """
  spades.py --careful -1 ${reads[0]} -2 ${reads[1]} -o spades_out -t 12 -m 24
  """
}

process UNICYCLER_SEQUENCE_ASSEMBLE_FOR_FASTP_FILTED_RAW_READS {
  label 'unicycler'
  tag "$sample"
  publishDir "${params.outdir}/genome_assemble_results/unicycler", mode: params.publish_dir_mode
  input:
  tuple val(sample), path (reads)
  output:
  tuple val(sample), path("unicycler_out") , emit: results
  script:

  """
  unicycler -1 ${reads[0]} -2 ${reads[1]} -o unicycler_out -t 12
  """
}

process QUAST_GENOME_ASSEMBLY_QUALITY_ASSESSMENT {  
  label 'quast'
  tag "$sample"
  publishDir "${params.outdir}/genome_assemble_reports/spades", mode: params.publish_dir_mode
  input:
  tuple val(sample), path (spades_fasta)
  tuple val(sample), path (unicycler_fasta)
  output:
  tuple val(sample), path("quast_out") , emit: results
  script:

  """
  quast -o quast_out/ -t 8 $spades_fasta $unicycler_fasta
  """

}


process MULTIQC_FOR_RAW_READS_FASTQC_RESULTS {
    label 'multiqc'
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/raw_reads_fastqc", mode: 'copy'

    input:
    path ('fastqc/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export fastqc/
    """
}

process MULTIQC_FOR_FASTP_READS_FILTER_RESULTS {
    label 'multiqc'
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/fastp", mode: 'copy'

    input:
    path ('fastp/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export fastp/
    """
}

process MULTIQC_FOR_CLEAN_READS_FASTQC_RESULTS {
    label 'multiqc'
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/raw_reads_fastqc", mode: 'copy'

    input:
    path ('fastqc/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export fastqc/
    """
}







workflow GET_ALL_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE {

  GET_NEXTFLOW_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_FASTQC_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_SAMTOOLS_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_MULTIQC_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_FASTP_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_SPADES_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_UNICYCLER_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_QUAST_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  GET_PROKKA_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
}

workflow FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS {
    take:
    reads         // channel: [ val(meta), [ reads ] ]
    main:

    raw_fastqc_html    = Channel.empty()
    raw_fastqc_zip     = Channel.empty()

    FASTQC_QUALITY_CHECK_FOR_RAW_READS ( reads ).html.set { raw_fastqc_html }
    raw_fastqc_zip     = FASTQC_QUALITY_CHECK_FOR_RAW_READS.out.zip


    fastp_reads        = reads
    fastp_log          = Channel.empty()
    fastp_json         = Channel.empty()
    fastp_html         = Channel.empty()

    /**  trim_reads = umi_reads
    trim_html  = Channel.empty()
    trim_zip   = Channel.empty()
    trim_log   = Channel.empty()
    trimgalore_version = Channel.empty()*/

    FASTP_READS_FILTER_FOR_RAW_READS ( fastp_reads ).reads.set { clean_reads }
    fastp_html  = FASTP_READS_FILTER_FOR_RAW_READS.out.html
    fastp_json  = FASTP_READS_FILTER_FOR_RAW_READS.out.json
    fastp_log   = FASTP_READS_FILTER_FOR_RAW_READS.out.log


    clean_fastqc_html    = Channel.empty()
    clean_fastqc_zip     = Channel.empty()

    FASTQC_QUALITY_CHECK_FOR_CLEAN_READS ( clean_reads ).html.set { clean_fastqc_html }
    clean_fastqc_zip     = FASTQC_QUALITY_CHECK_FOR_CLEAN_READS.out.zip

    emit:
    clean_reads_ch     = clean_reads
    clean_reads_salmon = clean_reads
    clean_reads_hisat2 = clean_reads
    raw_fastqc_html     //
    clean_fastqc_html   //
    raw_fastqc_zip
    clean_fastqc_zip         // channel: [ val(meta), [ zip ] ]
    fastp_html
    fastp_log          // channel: [ val(meta), [ html ] ]
    fastp_json           // channel: [ val(meta), [ zip ] ]

}




workflow {

  GET_ALL_SOFTWARE_VERSION_FOR_BAC_ASSEMBLE_PIPELINE (  )
  FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS ( raw_reads )
  SPADES_SEQUENCE_ASSEMBLE_FOR_FASTP_FILTED_RAW_READS ( FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS.out.clean_reads_ch )
}